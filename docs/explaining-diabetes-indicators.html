<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.4 Explaining diabetes indicators | Case Studies</title>
  <meta name="description" content="Case studies in machine learning." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="2.4 Explaining diabetes indicators | Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="Case studies in machine learning." />
  <meta name="github-repo" content="mini-pw/2021L-WB-Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.4 Explaining diabetes indicators | Case Studies" />
  
  <meta name="twitter:description" content="Case studies in machine learning." />
  <meta name="twitter:image" content="/images/cover.png" />

<meta name="author" content="Faculty of Mathematics and Information Science, Warsaw University of Technology" />


<meta name="date" content="2021-06-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="how-to-predict-the-probability-of-subsequent-blood-donations.html"/>
<link rel="next" href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>Case Studies</h3></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="technical-setup.html"><a href="technical-setup.html"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="explainable-artificial-intelligence-1.html"><a href="explainable-artificial-intelligence-1.html"><i class="fa fa-check"></i><b>1</b> Explainable Artificial Intelligence 1</a>
<ul>
<li class="chapter" data-level="1.1" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html"><i class="fa fa-check"></i><b>1.1</b> Explaining Credit Card Customers churns</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#introduction-and-motivation"><i class="fa fa-check"></i><b>1.1.1</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.1.2" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#methodology"><i class="fa fa-check"></i><b>1.1.2</b> Methodology</a></li>
<li class="chapter" data-level="1.1.3" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#local-explanations"><i class="fa fa-check"></i><b>1.1.3</b> Local explanations</a></li>
<li class="chapter" data-level="1.1.4" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#global-explanations"><i class="fa fa-check"></i><b>1.1.4</b> Global explanations</a></li>
<li class="chapter" data-level="1.1.5" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#summary"><i class="fa fa-check"></i><b>1.1.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html"><i class="fa fa-check"></i><b>1.2</b> XAI in real estate pricing: A case study</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html#abstract"><i class="fa fa-check"></i><b>1.2.1</b> Abstract</a></li>
<li class="chapter" data-level="1.2.2" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html#introduction"><i class="fa fa-check"></i><b>1.2.2</b> Introduction</a></li>
<li class="chapter" data-level="1.2.3" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html#related-work"><i class="fa fa-check"></i><b>1.2.3</b> Related Work</a></li>
<li class="chapter" data-level="1.2.4" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html#methodology-1"><i class="fa fa-check"></i><b>1.2.4</b> Methodology</a></li>
<li class="chapter" data-level="1.2.5" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html#results"><i class="fa fa-check"></i><b>1.2.5</b> Results</a></li>
<li class="chapter" data-level="1.2.6" data-path="xai-in-real-estate-pricing-a-case-study.html"><a href="xai-in-real-estate-pricing-a-case-study.html#summary-and-conclusions"><i class="fa fa-check"></i><b>1.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><i class="fa fa-check"></i><b>1.3</b> Coronary artery disease: Is it worth trusting ML when it comes to our health?</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html#abstract-1"><i class="fa fa-check"></i><b>1.3.1</b> Abstract</a></li>
<li class="chapter" data-level="1.3.2" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html#introduction-and-motivation-1"><i class="fa fa-check"></i><b>1.3.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.3.3" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html#related-work-1"><i class="fa fa-check"></i><b>1.3.3</b> Related Work</a></li>
<li class="chapter" data-level="1.3.4" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html#methodology-2"><i class="fa fa-check"></i><b>1.3.4</b> Methodology</a></li>
<li class="chapter" data-level="1.3.5" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html#results-1"><i class="fa fa-check"></i><b>1.3.5</b> Results</a></li>
<li class="chapter" data-level="1.3.6" data-path="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html"><a href="coronary-artery-disease-is-it-worth-trusting-ml-when-it-comes-to-our-health.html#summary-and-conclusions-1"><i class="fa fa-check"></i><b>1.3.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html"><i class="fa fa-check"></i><b>1.4</b> Red wine mystery: using explainable AI to inspect factors behind wine quality</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#abstract-2"><i class="fa fa-check"></i><b>1.4.1</b> Abstract</a></li>
<li class="chapter" data-level="1.4.2" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#introduction-and-motivation-2"><i class="fa fa-check"></i><b>1.4.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.4.3" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#methodology-3"><i class="fa fa-check"></i><b>1.4.3</b> Methodology</a></li>
<li class="chapter" data-level="1.4.4" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#global-explanations-3"><i class="fa fa-check"></i><b>1.4.4</b> Global explanations</a></li>
<li class="chapter" data-level="1.4.5" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#local-explanations-3"><i class="fa fa-check"></i><b>1.4.5</b> Local explanations</a></li>
<li class="chapter" data-level="1.4.6" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#confrontation-with-science"><i class="fa fa-check"></i><b>1.4.6</b> Confrontation with science</a></li>
<li class="chapter" data-level="1.4.7" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#summary-1"><i class="fa fa-check"></i><b>1.4.7</b> Summary</a></li>
<li class="chapter" data-level="1.4.8" data-path="xai1-explainable-wine.html"><a href="xai1-explainable-wine.html#conclusions"><i class="fa fa-check"></i><b>1.4.8</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html"><i class="fa fa-check"></i><b>1.5</b> Explanatory approach to modeling the risk of hotel booking cancellations</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html#abstract-3"><i class="fa fa-check"></i><b>1.5.1</b> Abstract</a></li>
<li class="chapter" data-level="1.5.2" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html#introduction-1"><i class="fa fa-check"></i><b>1.5.2</b> Introduction</a></li>
<li class="chapter" data-level="1.5.3" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html#dataset_models"><i class="fa fa-check"></i><b>1.5.3</b> Dataset and models</a></li>
<li class="chapter" data-level="1.5.4" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html#local"><i class="fa fa-check"></i><b>1.5.4</b> Local explanations</a></li>
<li class="chapter" data-level="1.5.5" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html#global-explanations-4"><i class="fa fa-check"></i><b>1.5.5</b> Global explanations</a></li>
<li class="chapter" data-level="1.5.6" data-path="xai1-explainable-hotels.html"><a href="xai1-explainable-hotels.html#summary-and-conclusions-2"><i class="fa fa-check"></i><b>1.5.6</b> Summary and conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="explainable-artificial-intelligence-2.html"><a href="explainable-artificial-intelligence-2.html"><i class="fa fa-check"></i><b>2</b> Explainable Artificial Intelligence 2</a>
<ul>
<li class="chapter" data-level="2.1" data-path="xai2-phones.html"><a href="xai2-phones.html"><i class="fa fa-check"></i><b>2.1</b> Does brand has an impact on smartphone prices?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="xai2-phones.html"><a href="xai2-phones.html#abstract-4"><i class="fa fa-check"></i><b>2.1.1</b> Abstract</a></li>
<li class="chapter" data-level="2.1.2" data-path="xai2-phones.html"><a href="xai2-phones.html#introduction-motivation-and-related-work"><i class="fa fa-check"></i><b>2.1.2</b> Introduction, motivation and related work</a></li>
<li class="chapter" data-level="2.1.3" data-path="xai2-phones.html"><a href="xai2-phones.html#methodology-4"><i class="fa fa-check"></i><b>2.1.3</b> Methodology</a></li>
<li class="chapter" data-level="2.1.4" data-path="xai2-phones.html"><a href="xai2-phones.html#results-2"><i class="fa fa-check"></i><b>2.1.4</b> Results</a></li>
<li class="chapter" data-level="2.1.5" data-path="xai2-phones.html"><a href="xai2-phones.html#summary-and-conclusion"><i class="fa fa-check"></i><b>2.1.5</b> Summary and conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html"><i class="fa fa-check"></i><b>2.2</b> Classifying people as good or bad credit risks</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html#abstract-5"><i class="fa fa-check"></i><b>2.2.1</b> Abstract</a></li>
<li class="chapter" data-level="2.2.2" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html#introduction-2"><i class="fa fa-check"></i><b>2.2.2</b> Introduction</a></li>
<li class="chapter" data-level="2.2.3" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html#dataset-and-models"><i class="fa fa-check"></i><b>2.2.3</b> Dataset and models</a></li>
<li class="chapter" data-level="2.2.4" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html#local-explanations-4"><i class="fa fa-check"></i><b>2.2.4</b> Local explanations</a></li>
<li class="chapter" data-level="2.2.5" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html#global-explanations-5"><i class="fa fa-check"></i><b>2.2.5</b> Global explanations</a></li>
<li class="chapter" data-level="2.2.6" data-path="xai2-german-credit-data.html"><a href="xai2-german-credit-data.html#summary-and-conclusions-3"><i class="fa fa-check"></i><b>2.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html"><i class="fa fa-check"></i><b>2.3</b> How to predict the probability of subsequent blood donations?</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#abstract-6"><i class="fa fa-check"></i><b>2.3.1</b> Abstract</a></li>
<li class="chapter" data-level="2.3.2" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#introduction-and-motivation-3"><i class="fa fa-check"></i><b>2.3.2</b> Introduction and motivation</a></li>
<li class="chapter" data-level="2.3.3" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#related-work-2"><i class="fa fa-check"></i><b>2.3.3</b> Related work</a></li>
<li class="chapter" data-level="2.3.4" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#data-analysis-and-pre-processing"><i class="fa fa-check"></i><b>2.3.4</b> Data analysis and pre-processing</a></li>
<li class="chapter" data-level="2.3.5" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#models-preparation-and-selection"><i class="fa fa-check"></i><b>2.3.5</b> Models preparation and selection</a></li>
<li class="chapter" data-level="2.3.6" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#global-explanations-6"><i class="fa fa-check"></i><b>2.3.6</b> Global explanations</a></li>
<li class="chapter" data-level="2.3.7" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#local-explanations-5"><i class="fa fa-check"></i><b>2.3.7</b> Local explanations</a></li>
<li class="chapter" data-level="2.3.8" data-path="how-to-predict-the-probability-of-subsequent-blood-donations.html"><a href="how-to-predict-the-probability-of-subsequent-blood-donations.html#conclusions-and-summary"><i class="fa fa-check"></i><b>2.3.8</b> Conclusions and summary</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html"><i class="fa fa-check"></i><b>2.4</b> Explaining diabetes indicators</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#abstract-7"><i class="fa fa-check"></i><b>2.4.1</b> Abstract</a></li>
<li class="chapter" data-level="2.4.2" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#introduction-3"><i class="fa fa-check"></i><b>2.4.2</b> Introduction</a></li>
<li class="chapter" data-level="2.4.3" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#methods"><i class="fa fa-check"></i><b>2.4.3</b> Methods</a></li>
<li class="chapter" data-level="2.4.4" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#explanations"><i class="fa fa-check"></i><b>2.4.4</b> Explanations</a></li>
<li class="chapter" data-level="2.4.5" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#results-3"><i class="fa fa-check"></i><b>2.4.5</b> Results</a></li>
<li class="chapter" data-level="2.4.6" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#expert-opinions"><i class="fa fa-check"></i><b>2.4.6</b> Expert opinions</a></li>
<li class="chapter" data-level="2.4.7" data-path="explaining-diabetes-indicators.html"><a href="explaining-diabetes-indicators.html#conclusions-1"><i class="fa fa-check"></i><b>2.4.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><i class="fa fa-check"></i><b>2.5</b> How the price of the house is influenced by neighborhood? XAI methods for interpretation the black box model</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html#abstract-8"><i class="fa fa-check"></i><b>2.5.1</b> Abstract</a></li>
<li class="chapter" data-level="2.5.2" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html#introduction-4"><i class="fa fa-check"></i><b>2.5.2</b> Introduction</a></li>
<li class="chapter" data-level="2.5.3" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html#literature"><i class="fa fa-check"></i><b>2.5.3</b> Literature</a></li>
<li class="chapter" data-level="2.5.4" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html#local-explanations-6"><i class="fa fa-check"></i><b>2.5.4</b> Local explanations</a></li>
<li class="chapter" data-level="2.5.5" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html#global-explanations-7"><i class="fa fa-check"></i><b>2.5.5</b> Global explanations</a></li>
<li class="chapter" data-level="2.5.6" data-path="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html"><a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html#conclusion"><i class="fa fa-check"></i><b>2.5.6</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="deep-learning-1.html"><a href="deep-learning-1.html"><i class="fa fa-check"></i><b>3</b> Deep Learning 1</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lungnet.html"><a href="lungnet.html"><i class="fa fa-check"></i><b>3.1</b> LungNet</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="lungnet.html"><a href="lungnet.html#introduction-5"><i class="fa fa-check"></i><b>3.1.1</b> Introduction</a></li>
<li class="chapter" data-level="3.1.2" data-path="lungnet.html"><a href="lungnet.html#data"><i class="fa fa-check"></i><b>3.1.2</b> Data</a></li>
<li class="chapter" data-level="3.1.3" data-path="lungnet.html"><a href="lungnet.html#original-model"><i class="fa fa-check"></i><b>3.1.3</b> Original model</a></li>
<li class="chapter" data-level="3.1.4" data-path="lungnet.html"><a href="lungnet.html#new-models"><i class="fa fa-check"></i><b>3.1.4</b> New models</a></li>
<li class="chapter" data-level="3.1.5" data-path="lungnet.html"><a href="lungnet.html#summary-2"><i class="fa fa-check"></i><b>3.1.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html"><i class="fa fa-check"></i><b>3.2</b> On the reproducibility of the BCDU-Net model</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html#abstract-9"><i class="fa fa-check"></i><b>3.2.1</b> Abstract</a></li>
<li class="chapter" data-level="3.2.2" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html#introduction-6"><i class="fa fa-check"></i><b>3.2.2</b> Introduction</a></li>
<li class="chapter" data-level="3.2.3" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html#reproduction-of-the-results"><i class="fa fa-check"></i><b>3.2.3</b> Reproduction of the results</a></li>
<li class="chapter" data-level="3.2.4" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html#further-experiments"><i class="fa fa-check"></i><b>3.2.4</b> Further experiments</a></li>
<li class="chapter" data-level="3.2.5" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html#other-tools-applied-to-the-model"><i class="fa fa-check"></i><b>3.2.5</b> Other tools applied to the model</a></li>
<li class="chapter" data-level="3.2.6" data-path="on-the-reproducibility-of-the-bcdu-net-model.html"><a href="on-the-reproducibility-of-the-bcdu-net-model.html#results-and-conclusions"><i class="fa fa-check"></i><b>3.2.6</b> Results and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html"><a href="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html"><i class="fa fa-check"></i><b>3.3</b> An Exploration of DeepCovidExplainer: Explainable COVID-19 Diagnosis from Chest X-rays</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html"><a href="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html#introduction-and-motivation-4"><i class="fa fa-check"></i><b>3.3.1</b> Introduction and motivation <!-- DONE --></a></li>
<li class="chapter" data-level="3.3.2" data-path="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html"><a href="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html#related-work-3"><i class="fa fa-check"></i><b>3.3.2</b> Related work</a></li>
<li class="chapter" data-level="3.3.3" data-path="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html"><a href="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html#our-work"><i class="fa fa-check"></i><b>3.3.3</b> Our work</a></li>
<li class="chapter" data-level="3.3.4" data-path="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html"><a href="an-exploration-of-deepcovidexplainer-explainable-covid-19-diagnosis-from-chest-x-rays.html#conclusions-and-summary-1"><i class="fa fa-check"></i><b>3.3.4</b> Conclusions and summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="erscovid.html"><a href="erscovid.html"><i class="fa fa-check"></i><b>3.4</b> ERSCovid</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="erscovid.html"><a href="erscovid.html#abstract-10"><i class="fa fa-check"></i><b>3.4.1</b> Abstract</a></li>
<li class="chapter" data-level="3.4.2" data-path="erscovid.html"><a href="erscovid.html#problem"><i class="fa fa-check"></i><b>3.4.2</b> Problem</a></li>
<li class="chapter" data-level="3.4.3" data-path="erscovid.html"><a href="erscovid.html#erscovid-workflow"><i class="fa fa-check"></i><b>3.4.3</b> ERSCovid workflow</a></li>
<li class="chapter" data-level="3.4.4" data-path="erscovid.html"><a href="erscovid.html#data-1"><i class="fa fa-check"></i><b>3.4.4</b> Data</a></li>
<li class="chapter" data-level="3.4.5" data-path="erscovid.html"><a href="erscovid.html#training"><i class="fa fa-check"></i><b>3.4.5</b> Training</a></li>
<li class="chapter" data-level="3.4.6" data-path="erscovid.html"><a href="erscovid.html#changes-to-original-model"><i class="fa fa-check"></i><b>3.4.6</b> Changes to original model</a></li>
<li class="chapter" data-level="3.4.7" data-path="erscovid.html"><a href="erscovid.html#summary-3"><i class="fa fa-check"></i><b>3.4.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html"><i class="fa fa-check"></i><b>3.5</b> Reproducing and modifying COVID-Net</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#abstract-11"><i class="fa fa-check"></i><b>3.5.1</b> Abstract</a></li>
<li class="chapter" data-level="3.5.2" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#introduction-and-motivation-5"><i class="fa fa-check"></i><b>3.5.2</b> Introduction and motivation</a></li>
<li class="chapter" data-level="3.5.3" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#related-work-4"><i class="fa fa-check"></i><b>3.5.3</b> Related work</a></li>
<li class="chapter" data-level="3.5.4" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#dataset-4"><i class="fa fa-check"></i><b>3.5.4</b> Dataset</a></li>
<li class="chapter" data-level="3.5.5" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#reproducibility"><i class="fa fa-check"></i><b>3.5.5</b> Reproducibility</a></li>
<li class="chapter" data-level="3.5.6" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#further-experiments-and-network-modifications"><i class="fa fa-check"></i><b>3.5.6</b> Further experiments and network modifications</a></li>
<li class="chapter" data-level="3.5.7" data-path="reproducing-and-modifying-covid-net.html"><a href="reproducing-and-modifying-covid-net.html#summary-4"><i class="fa fa-check"></i><b>3.5.7</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="deep-learning-2.html"><a href="deep-learning-2.html"><i class="fa fa-check"></i><b>4</b> Deep Learning 2</a>
<ul>
<li class="chapter" data-level="4.1" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><i class="fa fa-check"></i><b>4.1</b> What makes an article reproducible? Comparison of the FER+ paper and AxonDeepSeg</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#abstract-12"><i class="fa fa-check"></i><b>4.1.1</b> Abstract</a></li>
<li class="chapter" data-level="4.1.2" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#introduction-7"><i class="fa fa-check"></i><b>4.1.2</b> Introduction</a></li>
<li class="chapter" data-level="4.1.3" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#analyzing-the-ferplus-paper"><i class="fa fa-check"></i><b>4.1.3</b> Analyzing the FERPlus paper</a></li>
<li class="chapter" data-level="4.1.4" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#reproducibility-analysis"><i class="fa fa-check"></i><b>4.1.4</b> Reproducibility analysis</a></li>
<li class="chapter" data-level="4.1.5" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#analyzing-the-axondeepseg-paper"><i class="fa fa-check"></i><b>4.1.5</b> Analyzing the AxonDeepSeg paper</a></li>
<li class="chapter" data-level="4.1.6" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#reproducibility-analysis-1"><i class="fa fa-check"></i><b>4.1.6</b> Reproducibility analysis</a></li>
<li class="chapter" data-level="4.1.7" data-path="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html"><a href="what-makes-an-article-reproducible-comparison-of-the-fer-paper-and-axondeepseg.html#conclusion-1"><i class="fa fa-check"></i><b>4.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><i class="fa fa-check"></i><b>4.2</b> Can you classify histopathological data at home? Reproducing the ARA-CNN model’s data and performance.</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html#abstract-13"><i class="fa fa-check"></i><b>4.2.1</b> Abstract</a></li>
<li class="chapter" data-level="4.2.2" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html#introduction-8"><i class="fa fa-check"></i><b>4.2.2</b> Introduction</a></li>
<li class="chapter" data-level="4.2.3" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html#definition"><i class="fa fa-check"></i><b>4.2.3</b> Definition</a></li>
<li class="chapter" data-level="4.2.4" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html#methodology-5"><i class="fa fa-check"></i><b>4.2.4</b> Methodology</a></li>
<li class="chapter" data-level="4.2.5" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html#results-4"><i class="fa fa-check"></i><b>4.2.5</b> Results</a></li>
<li class="chapter" data-level="4.2.6" data-path="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html"><a href="can-you-classify-histopathological-data-at-home-reproducing-the-ara-cnn-models-data-and-performance-.html#summary-and-conclusions-4"><i class="fa fa-check"></i><b>4.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><a href="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><i class="fa fa-check"></i><b>4.3</b> Rethinking the U-Net architecture for multimodal biomedical image segmentation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><a href="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html#abstrac"><i class="fa fa-check"></i><b>4.3.1</b> Abstrac</a></li>
<li class="chapter" data-level="4.3.2" data-path="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><a href="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html#what-reproducibility-is"><i class="fa fa-check"></i><b>4.3.2</b> What Reproducibility Is?</a></li>
<li class="chapter" data-level="4.3.3" data-path="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><a href="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html#first-article-an-improvement-of-data-classification-using-random-multimodel-deep-learning-rmdl"><i class="fa fa-check"></i><b>4.3.3</b> First article (An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL) )</a></li>
<li class="chapter" data-level="4.3.4" data-path="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><a href="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html#second-article-multiresunet-rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation"><i class="fa fa-check"></i><b>4.3.4</b> Second article (MultiResUNet : Rethinking the U-Net architecture for multimodal biomedical image segmentation)</a></li>
<li class="chapter" data-level="4.3.5" data-path="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html"><a href="rethinking-the-u-net-architecture-for-multimodal-biomedical-image-segmentation.html#conclusion-2"><i class="fa fa-check"></i><b>4.3.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dl2-rmdl-unet.html"><a href="dl2-rmdl-unet.html"><i class="fa fa-check"></i><b>4.4</b> The reproducibility analysis of articles covering RMDL and UNet++ architectures churns</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dl2-rmdl-unet.html"><a href="dl2-rmdl-unet.html#abstract-14"><i class="fa fa-check"></i><b>4.4.1</b> Abstract</a></li>
<li class="chapter" data-level="4.4.2" data-path="dl2-rmdl-unet.html"><a href="dl2-rmdl-unet.html#reproduction"><i class="fa fa-check"></i><b>4.4.2</b> Reproduction</a></li>
<li class="chapter" data-level="4.4.3" data-path="dl2-rmdl-unet.html"><a href="dl2-rmdl-unet.html#random-multimodel-deep-learning-for-classification"><i class="fa fa-check"></i><b>4.4.3</b> Random Multimodel Deep Learning for Classification</a></li>
<li class="chapter" data-level="4.4.4" data-path="dl2-rmdl-unet.html"><a href="dl2-rmdl-unet.html#a-nested-u-net-architecture-for-medical-image-segmentation"><i class="fa fa-check"></i><b>4.4.4</b> A Nested U-Net Architecture for Medical Image Segmentation</a></li>
<li class="chapter" data-level="4.4.5" data-path="dl2-rmdl-unet.html"><a href="dl2-rmdl-unet.html#conclusions-2"><i class="fa fa-check"></i><b>4.4.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="can-you-trust-science-on-reproduction-in-deep-learning-.html"><a href="can-you-trust-science-on-reproduction-in-deep-learning-.html"><i class="fa fa-check"></i><b>4.5</b> Can you trust science? On Reproduction in Deep Learning.</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="can-you-trust-science-on-reproduction-in-deep-learning-.html"><a href="can-you-trust-science-on-reproduction-in-deep-learning-.html#abstract-15"><i class="fa fa-check"></i><b>4.5.1</b> Abstract</a></li>
<li class="chapter" data-level="4.5.2" data-path="can-you-trust-science-on-reproduction-in-deep-learning-.html"><a href="can-you-trust-science-on-reproduction-in-deep-learning-.html#introduction-10"><i class="fa fa-check"></i><b>4.5.2</b> Introduction</a></li>
<li class="chapter" data-level="4.5.3" data-path="can-you-trust-science-on-reproduction-in-deep-learning-.html"><a href="can-you-trust-science-on-reproduction-in-deep-learning-.html#methodology-6"><i class="fa fa-check"></i><b>4.5.3</b> Methodology</a></li>
<li class="chapter" data-level="4.5.4" data-path="can-you-trust-science-on-reproduction-in-deep-learning-.html"><a href="can-you-trust-science-on-reproduction-in-deep-learning-.html#result"><i class="fa fa-check"></i><b>4.5.4</b> Result</a></li>
<li class="chapter" data-level="4.5.5" data-path="can-you-trust-science-on-reproduction-in-deep-learning-.html"><a href="can-you-trust-science-on-reproduction-in-deep-learning-.html#discussion"><i class="fa fa-check"></i><b>4.5.5</b> Discussion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="machine-learning-1.html"><a href="machine-learning-1.html"><i class="fa fa-check"></i><b>5</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><a href="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><i class="fa fa-check"></i><b>5.1</b> Validation and comparison of COVID-19 mortality prediction models on multi-source data</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><a href="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html#abstract-16"><i class="fa fa-check"></i><b>5.1.1</b> Abstract</a></li>
<li class="chapter" data-level="5.1.2" data-path="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><a href="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html#introduction-11"><i class="fa fa-check"></i><b>5.1.2</b> Introduction</a></li>
<li class="chapter" data-level="5.1.3" data-path="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><a href="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html#data-description-1"><i class="fa fa-check"></i><b>5.1.3</b> Data description</a></li>
<li class="chapter" data-level="5.1.4" data-path="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><a href="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html#comparison-of-the-models"><i class="fa fa-check"></i><b>5.1.4</b> Comparison of the models</a></li>
<li class="chapter" data-level="5.1.5" data-path="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html"><a href="validation-and-comparison-of-covid-19-mortality-prediction-models-on-multi-source-data.html#conclusion-3"><i class="fa fa-check"></i><b>5.1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><i class="fa fa-check"></i><b>5.2</b> One model to fit them all: COVID-19 survival prediction using multinational data</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html#abstract-17"><i class="fa fa-check"></i><b>5.2.1</b> Abstract</a></li>
<li class="chapter" data-level="5.2.2" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html#introduction-12"><i class="fa fa-check"></i><b>5.2.2</b> Introduction</a></li>
<li class="chapter" data-level="5.2.3" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html#data-sources"><i class="fa fa-check"></i><b>5.2.3</b> Data sources</a></li>
<li class="chapter" data-level="5.2.4" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html#model-building"><i class="fa fa-check"></i><b>5.2.4</b> Model building</a></li>
<li class="chapter" data-level="5.2.5" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html#discussion-1"><i class="fa fa-check"></i><b>5.2.5</b> Discussion</a></li>
<li class="chapter" data-level="5.2.6" data-path="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html"><a href="one-model-to-fit-them-all-covid-19-survival-prediction-using-multinational-data.html#summary-6"><i class="fa fa-check"></i><b>5.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><i class="fa fa-check"></i><b>5.3</b> Transparent machine learning to support predicting COVID-19 infection risk based on chronic diseases</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#abstract-18"><i class="fa fa-check"></i><b>5.3.1</b> Abstract</a></li>
<li class="chapter" data-level="5.3.2" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#introduction-13"><i class="fa fa-check"></i><b>5.3.2</b> Introduction</a></li>
<li class="chapter" data-level="5.3.3" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#flaws"><i class="fa fa-check"></i><b>5.3.3</b> Flaws</a></li>
<li class="chapter" data-level="5.3.4" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#improvements"><i class="fa fa-check"></i><b>5.3.4</b> Improvements</a></li>
<li class="chapter" data-level="5.3.5" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#transparent-machine-learning"><i class="fa fa-check"></i><b>5.3.5</b> Transparent Machine Learning</a></li>
<li class="chapter" data-level="5.3.6" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#application"><i class="fa fa-check"></i><b>5.3.6</b> Application</a></li>
<li class="chapter" data-level="5.3.7" data-path="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html"><a href="transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html#conclusions-3"><i class="fa fa-check"></i><b>5.3.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><i class="fa fa-check"></i><b>5.4</b> Comparison of neural networks and tree-based models in the clinical prediction of the course of COVID-19 illness</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html#abstract-19"><i class="fa fa-check"></i><b>5.4.1</b> Abstract</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html#introduction-14"><i class="fa fa-check"></i><b>5.4.2</b> Introduction</a></li>
<li class="chapter" data-level="5.4.3" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html#methods-2"><i class="fa fa-check"></i><b>5.4.3</b> Methods</a></li>
<li class="chapter" data-level="5.4.4" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html#results-8"><i class="fa fa-check"></i><b>5.4.4</b> Results</a></li>
<li class="chapter" data-level="5.4.5" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html#discussion-2"><i class="fa fa-check"></i><b>5.4.5</b> Discussion</a></li>
<li class="chapter" data-level="5.4.6" data-path="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html"><a href="comparison-of-neural-networks-and-tree-based-models-in-the-clinical-prediction-of-the-course-of-covid-19-illness.html#source-code"><i class="fa fa-check"></i><b>5.4.6</b> Source code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rashomonml.html"><a href="rashomonml.html"><i class="fa fa-check"></i><b>6</b> RashomonML</a>
<ul>
<li class="chapter" data-level="6.1" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html"><i class="fa fa-check"></i><b>6.1</b> How to compare many good machine learning models?</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html#abstract-20"><i class="fa fa-check"></i><b>6.1.1</b> Abstract</a></li>
<li class="chapter" data-level="6.1.2" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html#introduction-15"><i class="fa fa-check"></i><b>6.1.2</b> Introduction</a></li>
<li class="chapter" data-level="6.1.3" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html#literature-review"><i class="fa fa-check"></i><b>6.1.3</b> Literature review</a></li>
<li class="chapter" data-level="6.1.4" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html#methodology-7"><i class="fa fa-check"></i><b>6.1.4</b> Methodology</a></li>
<li class="chapter" data-level="6.1.5" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html#results-9"><i class="fa fa-check"></i><b>6.1.5</b> Results</a></li>
<li class="chapter" data-level="6.1.6" data-path="how-to-compare-many-good-machine-learning-models.html"><a href="how-to-compare-many-good-machine-learning-models.html#summary-and-conclusions-5"><i class="fa fa-check"></i><b>6.1.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html"><i class="fa fa-check"></i><b>6.2</b> Analysis of models predicting death probability during ICU stays</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html#abstract-21"><i class="fa fa-check"></i><b>6.2.1</b> Abstract</a></li>
<li class="chapter" data-level="6.2.2" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html#introduction-16"><i class="fa fa-check"></i><b>6.2.2</b> Introduction</a></li>
<li class="chapter" data-level="6.2.3" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html#literature-review-1"><i class="fa fa-check"></i><b>6.2.3</b> Literature review</a></li>
<li class="chapter" data-level="6.2.4" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html#methodology-8"><i class="fa fa-check"></i><b>6.2.4</b> Methodology</a></li>
<li class="chapter" data-level="6.2.5" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html#results-10"><i class="fa fa-check"></i><b>6.2.5</b> Results</a></li>
<li class="chapter" data-level="6.2.6" data-path="analysis-of-models-predicting-death-probability-during-icu-stays.html"><a href="analysis-of-models-predicting-death-probability-during-icu-stays.html#summary-7"><i class="fa fa-check"></i><b>6.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="rashomon-ml-with-addition-of-dimensional-reduction.html"><a href="rashomon-ml-with-addition-of-dimensional-reduction.html"><i class="fa fa-check"></i><b>6.3</b> Rashomon ML with addition of dimensional reduction</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="rashomon-ml-with-addition-of-dimensional-reduction.html"><a href="rashomon-ml-with-addition-of-dimensional-reduction.html#abstract-22"><i class="fa fa-check"></i><b>6.3.1</b> Abstract</a></li>
<li class="chapter" data-level="6.3.2" data-path="rashomon-ml-with-addition-of-dimensional-reduction.html"><a href="rashomon-ml-with-addition-of-dimensional-reduction.html#introduction-and-related-works"><i class="fa fa-check"></i><b>6.3.2</b> Introduction and related works</a></li>
<li class="chapter" data-level="6.3.3" data-path="rashomon-ml-with-addition-of-dimensional-reduction.html"><a href="rashomon-ml-with-addition-of-dimensional-reduction.html#methodology-9"><i class="fa fa-check"></i><b>6.3.3</b> Methodology</a></li>
<li class="chapter" data-level="6.3.4" data-path="rashomon-ml-with-addition-of-dimensional-reduction.html"><a href="rashomon-ml-with-addition-of-dimensional-reduction.html#results-11"><i class="fa fa-check"></i><b>6.3.4</b> Results</a></li>
<li class="chapter" data-level="6.3.5" data-path="rashomon-ml-with-addition-of-dimensional-reduction.html"><a href="rashomon-ml-with-addition-of-dimensional-reduction.html#summary-and-conclusions-6"><i class="fa fa-check"></i><b>6.3.5</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><a href="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><i class="fa fa-check"></i><b>6.4</b> Rashomon sets on death prediction XGB models using MIMIC-III database</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><a href="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html#abstract-23"><i class="fa fa-check"></i><b>6.4.1</b> Abstract</a></li>
<li class="chapter" data-level="6.4.2" data-path="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><a href="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html#related-works-and-introduction"><i class="fa fa-check"></i><b>6.4.2</b> Related works and introduction</a></li>
<li class="chapter" data-level="6.4.3" data-path="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><a href="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html#methodology-10"><i class="fa fa-check"></i><b>6.4.3</b> Methodology</a></li>
<li class="chapter" data-level="6.4.4" data-path="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><a href="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html#results-12"><i class="fa fa-check"></i><b>6.4.4</b> Results</a></li>
<li class="chapter" data-level="6.4.5" data-path="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html"><a href="rashomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html#conclusions-4"><i class="fa fa-check"></i><b>6.4.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><i class="fa fa-check"></i><b>6.5</b> Rashomon sets of in-hospital mortality prediction random forest models</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#abstract-24"><i class="fa fa-check"></i><b>6.5.1</b> Abstract</a></li>
<li class="chapter" data-level="6.5.2" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#introduction-17"><i class="fa fa-check"></i><b>6.5.2</b> Introduction</a></li>
<li class="chapter" data-level="6.5.3" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#related-work-5"><i class="fa fa-check"></i><b>6.5.3</b> Related work</a></li>
<li class="chapter" data-level="6.5.4" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#mimic-iii-dataset"><i class="fa fa-check"></i><b>6.5.4</b> MIMIC-III Dataset</a></li>
<li class="chapter" data-level="6.5.5" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#rashomon-sets"><i class="fa fa-check"></i><b>6.5.5</b> Rashomon Sets</a></li>
<li class="chapter" data-level="6.5.6" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#results-13"><i class="fa fa-check"></i><b>6.5.6</b> Results</a></li>
<li class="chapter" data-level="6.5.7" data-path="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html"><a href="rashomon-sets-of-in-hospital-mortality-prediction-random-forest-models.html#conclusion-4"><i class="fa fa-check"></i><b>6.5.7</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="explaining-diabetes-indicators" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Explaining diabetes indicators</h2>
<p><em>Authors: Martyna Majchrzak, Jakub Jung, Paweł Niewiadowski (Warsaw University of Technology)</em></p>
<div id="abstract-7" class="section level3" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> Abstract</h3>
<p>Nowadays, Machine Learning is widely used in many more or less scientific fields. Some interesting ones include economy, social networking and medicine. Sometimes however we need not only a well performing model but also an understable one. The Explainable Atrificial Intelligence (XAI) is still pretty new concept and has a lot of potential for its use. In this paper we harness XAI methods for a real world medicine problem. We take a look at the diabetic data, build a decent model based on it and try to understand what conclusions the model has reached. As a result of our experiment we will try to understand what factors contribute to higher chance of diabetes occurence.</p>
<p><strong>Keywords</strong>: <em>Machine Learning, Explainable Artificial Intelligence, XAI, Classification, Diabetes</em></p>
</div>
<div id="introduction-3" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Introduction</h3>
<p>Machine Learning is a field of studies that is concerned with constructing algorithms that can <em>learn</em> using existing data and improve their performance with experience. Thus it allows predicting the unknown information with measurable certainty. With the rise in popularity of Machine Learning algorithms people started questioning the solutions obtained by computers’ calculations. Sometimes it does not matter how high the performance measures of the algorithm are, if we do not understand the reasoning behind its decisions. Therefore, the real problem is the lack of tools for model exploration, explanation (obtaining insight into model-based predictions) and examination (evaluation of model’s performance and understanding the weaknesses). As an answer a whole new branch of AI has been formed - Explainable Artificial Intelligence (XAI) <span class="citation">(<a href="#ref-2-4-XAI" role="doc-biblioref">Biecek and Burzykowski n.d.</a>)</span>.</p>
<p>The deep understanding of the model decision making is particularly important in medicine, where any misprediction can have fatal consequences.</p>
<p>Two areas which may benefit from the application of ML techniques in the medical field are diagnosis and outcome prediction. This includes a possibility for the identification of high risk for medical emergencies such as relapse or transition into another disease state. ML algorithms have recently been successfully employed to classify skin cancer using images with comparable accuracy to a trained dermatologist and to predict the progression from pre-diabetes to type 2 diabetes using routinely-collected electronic health record data <span class="citation">(<a href="#ref-2-4-ml-in-medicine" role="doc-biblioref"><span>“Machine learning in medicine”</span> n.d.</a>)</span>.</p>
<p>In this article we attempt to find the relationship between different biomarkers and positive diagnosis of diabetes based on the data of over 700 women of Indian ancestry (Pima tribe) collected by the National Institute of Diabetes and Digestive and Kidney Diseases. In order to do that, we used XAI tools on our black box models to present the decision making process of algorithms in understandable for humans way from which we could later draw conclusions.</p>
</div>
<div id="methods" class="section level3" number="2.4.3">
<h3><span class="header-section-number">2.4.3</span> Methods</h3>
<p>In this section we will discuss the methodology behind the conducted experiments.</p>
<p><strong>Dataset</strong></p>
<p>The dataset consists of 768 observations of 8 features being different biomarkers and 1 target variable (<code>class</code>) indicating that the woman was diagnosed with diabetes.</p>
<ul>
<li><code>preg</code> : number of pregnancies</li>
<li><code>plas</code> : plasma glucose concentration (mg/dL) at 2 hours in an OGTT (oral glucose tolerance test) - a test in which subject is given glucose and blood samples are taken afterwards to determine how quickly it is cleared from the blood</li>
<li><code>pres</code> : blood pressure (mm Hg)</li>
<li><code>skin</code> : triceps skinfold thickness (mm) measured at the back of the left arm. A measurement giving rough information about body fat percentage.</li>
<li><code>insu</code> : 2-hour serum insulin (mu U/ml)</li>
<li><code>mass</code> : BMI index (weight in kg/(height in meters)^2)</li>
<li><code>pedi</code> : diabetes pedigree function outcome, where DBF is a function that uses information from parents, grandparents, siblings, aunts, uncles, and first cousins and provides a measure of the expected genetic influence of affected and unaffected relatives on the subject’s eventual diabetes risk</li>
<li><code>age</code> : age (years)</li>
<li><code>class</code> (target): 1 if tested positive for diabetes, 0 otherwise</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:2-4-distributions"></span>
<img src="images/2-4-distributions.png" alt="Distributions of features and target in the original dataset" width="100%" />
<p class="caption">
Figure 2.1: Distributions of features and target in the original dataset
</p>
</div>
<p>The dataset did not have any missing data, however after analysing the feature distributions (Figure <a href="explaining-diabetes-indicators.html#fig:2-4-distributions">2.1</a>) and their meaning we found many 0 values that made no sense and were not physically possible (for example 0 value of <code>mass</code> which is BMI index - mass (in kilograms) divided by squared height (in meters)). According to an article about cost-sensitive classification <span class="citation">(<a href="#ref-2-4-cost" role="doc-biblioref">Turney 1995</a>)</span>, which addressed this dataset it is possible that some tests had never been carried out for some patients. This meant that the 0 values in our dataset (for features other than <code>preg</code> and <code>class</code> for which they absolutely make sense) were actually missing values.</p>
<p> </p>
<p><strong>Dataset versions</strong></p>
<p>During preprocessing and based on the observations of our first models 4 different versions of dataset were created and later used to train the models. First, the dataset was randomly divided into a training dataset (70% of data) and testing dataset (30% of data). Then the datasets were individually modificated in the following way:</p>
<ul>
<li><p><strong>original</strong> - base dataset with no modifications</p></li>
<li><p><strong>naomit</strong> - base dataset excluding observations with any missing values</p></li>
<li><p><strong>mice</strong> - base dataset with all missing values imputed with mice (Multivariate Imputation by Chained Equations) package using PMM method. <span class="citation">(<a href="#ref-2-4-mice" role="doc-biblioref">van Buuren and Groothuis-Oudshoorn 2011</a>)</span> Mice is suitable for this dataset, since the values are missing at random.</p></li>
<li><p><strong>skip</strong> - base dataset excluding features <code>skin</code>, <code>insu</code> and <code>pres</code> with missing values in <code>mass</code> and <code>plas</code> imputed with mice package</p></li>
</ul>
<p>The details of dataset versions are shown in table <a href="explaining-diabetes-indicators.html#tab:dataset-versions">2.1</a>.</p>
<table>
<caption><span id="tab:dataset-versions">Table 2.1: </span> Number of rows and columns in each version of the dataset: original, naomit, mice and skip.</caption>
<thead>
<tr class="header">
<th>Dataset</th>
<th>Rows Train</th>
<th>Rows Test</th>
<th>Columns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>original</td>
<td>537</td>
<td>231</td>
<td>9</td>
</tr>
<tr class="even">
<td>naomit</td>
<td>372</td>
<td>160</td>
<td>9</td>
</tr>
<tr class="odd">
<td>mice</td>
<td>537</td>
<td>231</td>
<td>9</td>
</tr>
<tr class="even">
<td>skip</td>
<td>537</td>
<td>231</td>
<td>6</td>
</tr>
</tbody>
</table>
<p> </p>
<p><strong>Measures</strong></p>
<p>For the assessment of the model in our experiment we will use three commonly known measures, available in <code>mlr</code> package <span class="citation">(<a href="#ref-2-4-mlr" role="doc-biblioref">Bischl et al. 2016</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li><strong>AUC - Area Under ROC Curve</strong></li>
</ol>
<p>An ROC curve (receiver operating characteristic curve) is a graph that shows the performance of a classification model at all classification thresholds. This curve plots two parameters:
TPR (True Positive Rate) and FPR (False Positive Rate), defined as:</p>
<p><span class="math inline">\(TPR=\frac{TP}{TP+FN}\)</span></p>
<p><span class="math inline">\(FPR=\frac{FP}{FP+TN}\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>BAC - Balanced Accuracy</strong></li>
</ol>
<p>This measure is a weighted accuracy, that is more suitable for datasets with imbalanced classes.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>FNR - False Negative Rate</strong></li>
</ol>
<p>It corresponds to the number of cases where model incorrectly fails to indicate the presence of a condition when it is present, divided by the number of all.</p>
<p><span class="math inline">\(FNR=\frac{FN}{TP+FN}\)</span></p>
<p>It is particularly important for medical data models, because it indicates how many sick patients are going to be categorised as healthy, and therefore not get any treatment.</p>
<p> </p>
<p><strong>Models</strong></p>
<p>To identify the models, that could potentially be efficient classificators on this dataset, we measured the AUC, Balanced Accuracy and False Negative Rate measures on 6 different classification models from <code>mlr</code> package:</p>
<p>Tree-based models:</p>
<ul>
<li><p><strong>Random Forest</strong> - Random Forest <span class="citation">(<a href="#ref-2-4-randomForest" role="doc-biblioref">Liaw and Wiener 2002</a>)</span></p></li>
<li><p><strong>Ranger</strong> - Random regression forest <span class="citation">(<a href="#ref-2-4-ranger" role="doc-biblioref">Wright and Ziegler 2017</a>)</span></p></li>
</ul>
<p>Boosting models:</p>
<ul>
<li><p><strong>Ada</strong> - Adaptive Boosting <span class="citation">(<a href="#ref-2-4-ada" role="doc-biblioref">Culp et al. 2016</a>)</span></p></li>
<li><p><strong>GBM</strong> - Gradient Boosting Machine <span class="citation">(<a href="#ref-2-4-gbm" role="doc-biblioref">B. Greenwell et al. 2020</a>)</span></p></li>
</ul>
<p>Other:</p>
<ul>
<li><p><strong>Binomial</strong> - Binomial Regression <span class="citation">(<a href="#ref-2-4-stats" role="doc-biblioref">R Core Team 2021</a>)</span></p></li>
<li><p><strong>Naive Bayes</strong> - Naive Bayes <span class="citation">(<a href="#ref-2-4-e1071" role="doc-biblioref">Meyer et al. 2020</a>)</span></p></li>
</ul>
</div>
<div id="explanations" class="section level3" number="2.4.4">
<h3><span class="header-section-number">2.4.4</span> Explanations</h3>
<p>In this section we will take time to introduce some model explanations that we will be using later. Feel free to use this chapter as reference for quick overview. For more in-depth knowledge please refer to paper <span class="citation">(<a href="#ref-2-4-XAI" role="doc-biblioref">Biecek and Burzykowski n.d.</a>)</span> All images in this section are also taken from this article.
Explanations themselves were implemented in the DALEX <span class="citation">(<a href="#ref-2-4-DALEX" role="doc-biblioref">Biecek 2018</a>)</span> and DALEXtra <span class="citation">(<a href="#ref-2-4-DALEXtra" role="doc-biblioref">Maksymiuk and Biecek 2020</a>)</span> package.</p>
<p><strong>Local Explanations</strong></p>
<p>Local explanations allow us to better understand model’s prediction from the level of single observations. This can be useful when we want to evaluate predictions for certain instances. For example, which values have the most importance for the particular observations, or how the change in variables would impact the result. Local explanations combined with professional expertise could sometimes hint towards potential problems with the model in case they contradict each other.</p>
<ul>
<li><strong>Break Down</strong></li>
</ul>
<p>In Break Down explanation <span class="citation">(<a href="#ref-xai1-breakdown" role="doc-biblioref">Staniak and Biecek 2018</a>)</span> all observations start from the same base that is the mean prediction for all data. Next steps consist of fixing consecutive variables on values from the observation in question and measuring the change in mean prediction that is now calculated with some of the values fixed. This shift in mean prediction is interpreted as the impact of this variable’s value on prediction for this observation. Figure <a href="explaining-diabetes-indicators.html#fig:2-4-break-down">2.2</a> shows the corresponding steps.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-break-down"></span>
<img src="images/2-4-break_down_distr.png" alt="Panel A shows the distribution of target values: in the first row overall distribution, and on the subsequent ones - distribution from the previous row with fixed value of the variable written on the left. For example, in the third row values of age and class variables are fixed. The red dot represents the mean of the distribution. On panel B only the mean value is shown. On panel C the change in mean (average impact) is calculated and assigned to corresponding variables." width="100%" />
<p class="caption">
Figure 2.2: Panel A shows the distribution of target values: in the first row overall distribution, and on the subsequent ones - distribution from the previous row with fixed value of the variable written on the left. For example, in the third row values of age and class variables are fixed. The red dot represents the mean of the distribution. On panel B only the mean value is shown. On panel C the change in mean (average impact) is calculated and assigned to corresponding variables.
</p>
</div>
<p>A big drawback for this method is how the order of variable can influence the explanation outcome. This problem occurs most often as a result of existing interactions between variables as seen in figure <a href="explaining-diabetes-indicators.html#fig:2-4-ordering">2.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-ordering"></span>
<img src="images/2-4-ordering.png" alt="Break Down output for the same observation but with different order of variables. Variables age and class interact with each other. Hence the change in order results in different values on plots." width="100%" />
<p class="caption">
Figure 2.3: Break Down output for the same observation but with different order of variables. Variables age and class interact with each other. Hence the change in order results in different values on plots.
</p>
</div>
<ul>
<li><strong>Shap</strong></li>
</ul>
<p>Shap <span class="citation">(<a href="#ref-xai1-shapleyvalues" role="doc-biblioref">Lundberg and Lee 2017</a>)</span> is a direct response to the biggest problem of Break Down method that is the ordering chosen for explanation being able to alter the results. Shap takes a number of permutation and calculates the average response of Break Down on these permutations. More permutations result in more stable explanations. Exemplary output is shown in figure <a href="explaining-diabetes-indicators.html#fig:2-4-shap-ordering">2.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-shap-ordering"></span>
<img src="images/2-4-shap_ordering.png" alt="Shap output for Johny D observation. Average impact of the variable on the prediction calculated with Break Down for 10 permutations, with boxplots showing the distribution of impacts from different permutations." width="100%" />
<p class="caption">
Figure 2.4: Shap output for Johny D observation. Average impact of the variable on the prediction calculated with Break Down for 10 permutations, with boxplots showing the distribution of impacts from different permutations.
</p>
</div>
<ul>
<li><strong>Lime</strong></li>
</ul>
<p>The essence of Lime <span class="citation">(<a href="#ref-xai1-lime" role="doc-biblioref">Ribeiro et al. 2016</a>)</span> is to locally approximate the black box model with a glass box one. Then we can use it for local explanations that should yield results appropriate for the black box. Firstly, we generate data “close” to our observation (also called Point of Interest) and make predictions with black box model. Based on those predictions we try to fit the glass box model that accurately predicts those observations. In result we receive a glass box model that should behave the same as original model as long as we remain close to the Point of interest. Figure <a href="explaining-diabetes-indicators.html#fig:2-4-lime-introduction">2.5</a> describes the idea.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-lime-introduction"></span>
<img src="images/2-4-lime_introduction.png" alt="Colored areas correspond to different prediction for the black box model. Black cross is our Point of Interest and circles are generated data. The line represents our simpler model that approximates original model around Point of Interest." width="100%" />
<p class="caption">
Figure 2.5: Colored areas correspond to different prediction for the black box model. Black cross is our Point of Interest and circles are generated data. The line represents our simpler model that approximates original model around Point of Interest.
</p>
</div>
<p>This method is often used for datasets consisting of many variables. Methods like Break down and Shap come out short in these situations.</p>
<ul>
<li><strong>Ceteris Paribus</strong></li>
</ul>
<p>Ceteris Paribus <span class="citation">(<a href="#ref-EMA" role="doc-biblioref">Biecek and Burzykowski 2021</a>)</span> is a Latin phrase meaning “all else unchanged.” This accurately describes what it does. For the certain observation we take values that are interesting to us and observe how the prediction changes as we change values in those columns one at a time. This can yield interesting conclusions about change in values and its impact on predictions. Figures <a href="explaining-diabetes-indicators.html#fig:2-4-titanicCeterisProfile01E">2.6</a> and <a href="explaining-diabetes-indicators.html#fig:2-4-ceteris">2.7</a> show prediction change as response to variable change.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-titanicCeterisProfile01E"></span>
<img src="images/2-4-titanicCeterisProfile01E-1.png" alt="Ceteris-paribus profile for observation Henry using Logistic Regression and Random Forest models. Shape of lines shows how the prediction would change depending on the value of age and fare variables with all the other variables unchanged. Dot shows the real value and models prediction for this particular observation." width="100%" />
<p class="caption">
Figure 2.6: Ceteris-paribus profile for observation Henry using Logistic Regression and Random Forest models. Shape of lines shows how the prediction would change depending on the value of age and fare variables with all the other variables unchanged. Dot shows the real value and models prediction for this particular observation.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:2-4-ceteris"></span>
<img src="images/2-4-titanicCeterisProfile01D-1.png" alt=" Ceteris Paribus profile using Random Forest for two observations.Shape of lines shows how the prediction would change depending on the value of age and fare variables with all the other variables unchanged. Dot shows the real value and models prediction for this particular observation." width="100%" />
<p class="caption">
Figure 2.7:  Ceteris Paribus profile using Random Forest for two observations.Shape of lines shows how the prediction would change depending on the value of age and fare variables with all the other variables unchanged. Dot shows the real value and models prediction for this particular observation.
</p>
</div>
<p>Ceteris Paribus is very popular due to its simplicity and interpretability. The biggest drawback however is the possibility of unpredictable or misleading results. For example, with fixed variable age set to 18, predicting outcome for a significant number of pregnancies does not make sense. It is also hard to capture interactions when working with variables separately.</p>
<p><strong>Global Explanations</strong></p>
<p>As the name implies in global explanations we look at variables from the perspective of whole dataset. We can check the importance of variable for the model or analyze average impact of certain values on predictions.</p>
<ul>
<li><strong>Feature Importance</strong></li>
</ul>
<p>The main idea behind Feature Importance <span class="citation">(<a href="#ref-2-4-pfi" role="doc-biblioref">Fisher et al. 2018</a>)</span> is measuring how important each variable is for model’s predictions. To do that we measure the change in AUC after permutating values of each variable. The bigger the change, the bigger importance of variable. To stabilize the results, we can measure average change for a number of permutations. In figure <a href="explaining-diabetes-indicators.html#fig:2-4-TitanicRFFeatImp">2.8</a> we can see that variable gender is the most important for model’s prediction.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-TitanicRFFeatImp"></span>
<img src="images/2-4-TitanicRFFeatImp10-1.png" alt="The average change in AUC after permutating values of each variable (Feature Importance) for 10 permutations, with boxplots showing the distribution of changes from different permutations." width="100%" />
<p class="caption">
Figure 2.8: The average change in AUC after permutating values of each variable (Feature Importance) for 10 permutations, with boxplots showing the distribution of changes from different permutations.
</p>
</div>
<ul>
<li><strong>Partial Dependence</strong></li>
</ul>
<p>To put it short, Partial Dependence <span class="citation">(<a href="#ref-2-4-pdp" role="doc-biblioref">B. M. Greenwell 2017</a>)</span> is the average of Ceteris Paribus for whole data. This results in average importance and impact of variable and its values. The similarities can be observed in figure <a href="explaining-diabetes-indicators.html#fig:2-4-pdpIntuition-1">2.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-pdpIntuition-1"></span>
<img src="images/2-4-pdpIntuition-1.png" alt="On the left panel, Ceteris Paribus profile for age variable for multiple observations. On the right, their average as Partial Dependence, showing how the prediction would change depending on the value of age." width="100%" />
<p class="caption">
Figure 2.9: On the left panel, Ceteris Paribus profile for age variable for multiple observations. On the right, their average as Partial Dependence, showing how the prediction would change depending on the value of age.
</p>
</div>
<p>As we can see observations can return different shapes for Ceteris Paribus, hence averaging them could mean loss of information. To answer this problem Partial Dependence implements grouping and clustering that could show the difference as shown in figure <a href="explaining-diabetes-indicators.html#fig:2-4-pdpPart5-1">2.10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-pdpPart5-1"></span>
<img src="images/2-4-pdpPart5-1.png" alt="Partial Dependence of the prediction on the age variable for Random Forest model, with the observations grouped by gender. Shows how the average prediction differs for male and female passengers" width="100%" />
<p class="caption">
Figure 2.10: Partial Dependence of the prediction on the age variable for Random Forest model, with the observations grouped by gender. Shows how the average prediction differs for male and female passengers
</p>
</div>
<p>Like Ceteris Paribus, this method is very simple and understandable. However, it also carries over the same problems resulting from correlated variables.</p>
<ul>
<li><strong>Accumulated Dependence</strong></li>
</ul>
<p>Also referred as Accumulated-Local Dependence <span class="citation">(<a href="#ref-xai1-ale" role="doc-biblioref">Apley and Zhu 2020</a>)</span>. It is the direct answer for correlation issue in Partial Dependence. The construction of Accumulated Dependence is the same as in Ceteris Paribus. The only difference being how the observations are summarized. Partial Dependence uses marginal distribution while Accumulated Dependence uses conditional distribution. This means that when there are at most negligible correlations, Accumulated Dependence yields results very similar to Partial Dependence.</p>
</div>
<div id="results-3" class="section level3" number="2.4.5">
<h3><span class="header-section-number">2.4.5</span> Results</h3>
<p><strong>Dataset versions comparison</strong></p>
<p>We compared the performance of the Ranger model with default values on the testing datasets, using AUC, Balanced Accuracy and False Negative Rate measures. The results are shown in the table <a href="explaining-diabetes-indicators.html#tab:dataset-comparison">2.2</a>.</p>
<table>
<caption><span id="tab:dataset-comparison">Table 2.2: </span> The value of performance measures AUC, Balanced Accuracy and False Negative Rate of Ranger model on all dataset versions: original, naomit, mice and skip. For measures AUC and BAC higher value indicates better model, while for FNR - worse model.</caption>
<thead>
<tr class="header">
<th></th>
<th>AUC</th>
<th>BAC</th>
<th>FNR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>original</td>
<td>0.8173</td>
<td>0.7141</td>
<td>0.1529</td>
</tr>
<tr class="even">
<td>naomit</td>
<td>0.8481</td>
<td>0.7260</td>
<td>0.0991</td>
</tr>
<tr class="odd">
<td>mice</td>
<td>0.8109</td>
<td>0.6736</td>
<td>0.1529</td>
</tr>
<tr class="even">
<td>skip</td>
<td>0.8095</td>
<td>0.6779</td>
<td>0.1847</td>
</tr>
</tbody>
</table>
<p>The <code>naomit</code> dataset has the best scores, however, using this dataset version may cause the loss of valuable information. Because of that, we are going to use <code>original</code> and <code>skip</code> versions for further analysis.</p>
<p> </p>
<p><strong>Model comparison</strong></p>
<p>The models were checked with AUC, Balanced Accuracy and False Negative Rate measures on both <code>original</code> and <code>skip</code> dataset version, with the results shown in tables <a href="explaining-diabetes-indicators.html#tab:dataset-original">2.3</a> and <a href="explaining-diabetes-indicators.html#tab:dataset-skip">2.4</a>.</p>
<ul>
<li><strong>Data Original</strong></li>
</ul>
<table>
<caption><span id="tab:dataset-original">Table 2.3: </span> The value of performance measures AUC, Balanced Accuracy and False Negative Rate on original dataset version using 6 classification models. For measures AUC and BAC higher value indicates better model, while for FNR - worse model.</caption>
<thead>
<tr class="header">
<th></th>
<th>AUC</th>
<th>BAC</th>
<th>FNR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ranger</td>
<td>0.8194</td>
<td>0.7077</td>
<td>0.1656</td>
</tr>
<tr class="even">
<td>Ada</td>
<td>0.8101</td>
<td>0.7487</td>
<td>0.1783</td>
</tr>
<tr class="odd">
<td>Binomial</td>
<td>0.8215</td>
<td>0.7030</td>
<td>0.1210</td>
</tr>
<tr class="even">
<td>GBM</td>
<td>0.8186</td>
<td>0.6942</td>
<td>0.1656</td>
</tr>
<tr class="odd">
<td>NaiveBayes</td>
<td>0.8116</td>
<td>0.6946</td>
<td>0.1783</td>
</tr>
<tr class="even">
<td>RandomForest</td>
<td>0.8155</td>
<td>0.7077</td>
<td>0.1656</td>
</tr>
</tbody>
</table>
<p>The measure values between models are quite similar, however Ada has the best Balanced Accuracy and Binomial has the lowest False Negative Rate.</p>
<ul>
<li><strong>Data Skip</strong></li>
</ul>
<table>
<caption><span id="tab:dataset-skip">Table 2.4: </span> The value of performance measures AUC, Balanced Accuracy and False Negative Rate on dataset version with skipped columns, using 6 classification models. For measures AUC and BAC higher value indicates better model, while for FNR - worse model.</caption>
<thead>
<tr class="header">
<th></th>
<th>AUC</th>
<th>BAC</th>
<th>FNR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ranger</td>
<td>0.8134</td>
<td>0.7014</td>
<td>0.1783</td>
</tr>
<tr class="even">
<td>Ada</td>
<td>0.8230</td>
<td>0.7153</td>
<td>0.1911</td>
</tr>
<tr class="odd">
<td>Binomial</td>
<td>0.8223</td>
<td>0.7197</td>
<td>0.1146</td>
</tr>
<tr class="even">
<td>GBM</td>
<td>0.8146</td>
<td>0.6875</td>
<td>0.1656</td>
</tr>
<tr class="odd">
<td>NaiveBayes</td>
<td>0.8276</td>
<td>0.7372</td>
<td>0.1338</td>
</tr>
<tr class="even">
<td>RandomForest</td>
<td>0.8061</td>
<td>0.7018</td>
<td>0.1911</td>
</tr>
</tbody>
</table>
<p>On this dataset version Binomial still has the lowest <code>FNR</code>, but no model has a significantly better results than the Ranger model.</p>
<p><strong>Tuned models</strong></p>
<p>Better results can be achieved with the use of parameter tuning.
Based on the results, two models: Ranger and Ada were chosen for further experiments. Hyperparameter tuning using random grid search and FNR as a minimalized measure was performed, resulting in classificators with the following parameter values:</p>
<ol style="list-style-type: decimal">
<li><strong>Tuned Ranger</strong></li>
</ol>
<ul>
<li>num.trees = 776,</li>
<li>mtry = 1,</li>
<li>min.node.size = 8,</li>
<li>splitrule = “extratrees”</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Tuned Ada</strong></li>
</ol>
<ul>
<li>loss = ‘logistic,’</li>
<li>type = ‘discrete,’</li>
<li>iter = 81,</li>
<li>max.iter = 3,</li>
<li>minsplit = 45,</li>
<li>minbucket = 4,</li>
<li>maxdepth = 1</li>
</ul>
<p>The tuned models were checked with AUC, Balanced Accuracy and False Negative Rate measures on <code>skip</code> dataset version, with the results shown in table <a href="explaining-diabetes-indicators.html#tab:dataset-tuned">2.5</a>.</p>
<table>
<caption><span id="tab:dataset-tuned">Table 2.5: </span> The value of performance measures AUC, Balanced Accuracy and False Negative Rate on 2 dataset versions: original and with skipped columns, using tuned classification models Ranger and Ada. For measures AUC and BAC higher value indicates better model, while for FNR - worse model.</caption>
<thead>
<tr class="header">
<th></th>
<th>AUC</th>
<th>BAC</th>
<th>FNR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tuned Ranger</td>
<td>0.8664</td>
<td>0.7375</td>
<td>0.1111</td>
</tr>
<tr class="even">
<td>Tuned Ada</td>
<td>0.8447</td>
<td>0.6937</td>
<td>0.1528</td>
</tr>
</tbody>
</table>
<p>The performance measures of tuned models are higher than the original ones and ranger still proves to be a better classificator on this dataset.</p>
<p> </p>
<p><strong>Global explanations results</strong></p>
<p>In this section we’ll explain the prediction of the Ranger and Ada model on th <code>skip</code> dataset version.</p>
<p>Figure <a href="explaining-diabetes-indicators.html#fig:2-4-feature-importance">2.11</a> shows Feature Importance for both Ada and Ranger models. As we can see, both agree with each other as to what variables are most important to them. Their predictions are mostly based on the values of <code>plas</code> variable and then <code>mass</code> and <code>age</code> come second.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-feature-importance"></span>
<img src="images/2-4-feature-importance.png" alt=" Variable importance for Ada and Ranger based on average AUC loss after 10 permutations of this variable. Boxplots show the distribution of changes from different permutations." width="100%" />
<p class="caption">
Figure 2.11:  Variable importance for Ada and Ranger based on average AUC loss after 10 permutations of this variable. Boxplots show the distribution of changes from different permutations.
</p>
</div>
<p>Partial Dependence profile seen in figure <a href="explaining-diabetes-indicators.html#fig:2-4-pdp">2.12</a> gives us perhaps the most interesting results. Firstly, they are adequate to Feature importance in Figure <a href="explaining-diabetes-indicators.html#fig:2-4-feature-importance">2.11</a>. The more important variables return wider range of average prediction and less important give less varied predictions. Secondly, we can observe the difference in model’s inner characteristics based on the shape of their PDP functions. Ada is more edgy and straight while Ranger is more smooth.
Based on results yielded by PDP and according to these two models we can conclude that, generally speaking, the bigger the values the higher the chance of positive diabetes test result.</p>
<p>Some other key observations include:</p>
<ul>
<li>For Ada model, little to none impact by change of <code>age</code> after 35 years of living. For ranger, a peak in the prediction value around the age of 50.</li>
<li>A sudden increase in prediction with <code>mass</code> reaching 30 (the border of obesity in BMI model).</li>
<li>Almost no change for Ada prediction with change of <code>pedi</code>.</li>
<li>A slight increase in prediction with 7th <code>pregnancy</code>.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:2-4-pdp"></span>
<img src="images/2-4-pdp.png" alt="Average predictions with PDP for Ada and Ranger, showing how the prediction would change depending on the value of given variable. Shows the trend, that for most cases the bigger the value of variable the higher the chance of positive diabetes test result." width="100%" />
<p class="caption">
Figure 2.12: Average predictions with PDP for Ada and Ranger, showing how the prediction would change depending on the value of given variable. Shows the trend, that for most cases the bigger the value of variable the higher the chance of positive diabetes test result.
</p>
</div>
<p>Accumulated Dependence gave us similar results to Partial Dependence, thus we can conclude that our dataset does not contain any problematic correlations. Comparison between PD and AD is plotted on the figure <a href="explaining-diabetes-indicators.html#fig:2-4-pdp-ale-mass">2.13</a> for <code>mass</code> variable.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-pdp-ale-mass"></span>
<img src="images/2-4-pdp-ale-mass.png" alt="Average predictions with PDP and ALE for Ada and Ranger. Simmilar shape of the PDP and ALE plots for each respective model indicates no problematic correlations with `mass` variable." width="100%" />
<p class="caption">
Figure 2.13: Average predictions with PDP and ALE for Ada and Ranger. Simmilar shape of the PDP and ALE plots for each respective model indicates no problematic correlations with <code>mass</code> variable.
</p>
</div>
<p> </p>
<p><strong>Local explanations results</strong></p>
<p>Local explainations for Ada and Ranger models are very similar, therefore we focus on the one with a bit better metrics - Ranger.</p>
<p>Ceteris Paribus shows us results adequate to Pratial Dependence Profile (See Figures <a href="explaining-diabetes-indicators.html#fig:2-4-ceteris-paribus">2.14</a> and <a href="explaining-diabetes-indicators.html#fig:2-4-lime-190">2.15</a>). Predictions are very consistent in variable <code>plas</code>. However in <code>age</code> and <code>pedi</code> cases we can spot different trends in prediction behaviour. This could hint towards potential interactions between variables. As for <code>mass</code> and <code>preg</code> they differ mostly in initial prediction value. Overall tendency is rising.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-ceteris-paribus"></span>
<img src="images/2-4-ceteris-paribus.png" alt="Ceteris Paribus predictions for five selected observations: 140, 190, 202, 214 and 74. Plot shows how the prediction would change depending on the value of given variable. Dot shows the real value and models prediction for this particular observation." width="100%" />
<p class="caption">
Figure 2.14: Ceteris Paribus predictions for five selected observations: 140, 190, 202, 214 and 74. Plot shows how the prediction would change depending on the value of given variable. Dot shows the real value and models prediction for this particular observation.
</p>
</div>
<p><strong><em>Observation 190</em></strong></p>
<p>Let us analyze observation 190 in more detail. Lime explanation (Figure <a href="explaining-diabetes-indicators.html#fig:2-4-lime-190">2.15</a>) tells us three biggest factors approximated by glass box model. Having <code>plas</code> lower than 100 in our case has significant negative impact on positive diagnosis of diabetes. On the other hand, having high <code>mass</code> value and being in 30’s adds to our probability of having diabetes.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-lime-190"></span>
<img src="images/2-4-lime_190.png" alt="Lime output for observation 190. The predicted value was 0.162, indicating a healthy patient. This prediction was mostly influenced by a low value of `plas` variable, lowering the risk of diabetes. Patients age and mass slighly heightened the risk." width="100%" />
<p class="caption">
Figure 2.15: Lime output for observation 190. The predicted value was 0.162, indicating a healthy patient. This prediction was mostly influenced by a low value of <code>plas</code> variable, lowering the risk of diabetes. Patients age and mass slighly heightened the risk.
</p>
</div>
<p>Breakdown and Shap (Figures <a href="explaining-diabetes-indicators.html#fig:2-4-bd-190">2.16</a> and <a href="explaining-diabetes-indicators.html#fig:2-4-shap-190">2.17</a>) as opposed to Lime give us prediction change for exact values, not intervals. Because of that the results may be different. So is the case with the <code>age</code> variable which behaves differently for Lime. According to Breakdown and Shap being 29 years of age slightly decreases prediction but Lime says otherwise. Not only it increases but also by a significant amount. Other variables seem to match their impact if just scaled down a bit for BD and Shap.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-bd-190"></span>
<img src="images/2-4-bd_190.png" alt="Breakdown output for observation 190, influences of each variable of the prediction - red indicates lowering, and green heightening the prediction value" width="100%" />
<p class="caption">
Figure 2.16: Breakdown output for observation 190, influences of each variable of the prediction - red indicates lowering, and green heightening the prediction value
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:2-4-shap-190"></span>
<img src="images/2-4-shap_190.png" alt="Shap output for observation 190. Average impact of the variable on the prediction calculated with Break Down for 10 permutations, with boxplots showing the distribution of impacts from different permutations" width="100%" />
<p class="caption">
Figure 2.17: Shap output for observation 190. Average impact of the variable on the prediction calculated with Break Down for 10 permutations, with boxplots showing the distribution of impacts from different permutations
</p>
</div>
<p><strong><em>Observation 214</em></strong></p>
<p>The next observation we analyze is observation 214 for which the model has a prediction of about 44% for positive diagnosis of diabetes. Lime explanation (Figure <a href="explaining-diabetes-indicators.html#fig:2-4-lime-214">2.18</a>) tells us that three biggest factors for this prediction are <code>pedi</code>, <code>plas</code> and <code>mass</code>. This time the first one is <code>pedi</code> with high value of over 0.5. Despite high values of <code>plas</code> (over 115) and <code>mass</code> (over 33), the prediction is higher than average for this dataset but still lower than 50%.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-lime-214"></span>
<img src="images/2-4-lime_214.png" alt="Lime output for observation 214. The predicted value was 0.446, indicating a healthy patient, but with less certainty. This prediction was mostly influenced by higher values of `pedi`, `plas` and `mass` variables." width="100%" />
<p class="caption">
Figure 2.18: Lime output for observation 214. The predicted value was 0.446, indicating a healthy patient, but with less certainty. This prediction was mostly influenced by higher values of <code>pedi</code>, <code>plas</code> and <code>mass</code> variables.
</p>
</div>
<p>Breakdown and Shap (Figures <a href="explaining-diabetes-indicators.html#fig:2-4-bd-214">2.19</a> and <a href="explaining-diabetes-indicators.html#fig:2-4-shap-214">2.20</a>) show similar results, just toned down. The biggest difference is the impact of <code>pedi</code> which in Lime was nearly twice as big as the impact of <code>plas</code> and <code>mass</code>. The only value making it less probable that the observation would have diabetes is <code>age</code> equal to 28.</p>
<div class="figure" style="text-align: center"><span id="fig:2-4-bd-214"></span>
<img src="images/2-4-bd_214.png" alt="Breakdown output for observation 214, influences of each variable of the prediction - red indicates lowering, and green heightening the prediction value" width="100%" />
<p class="caption">
Figure 2.19: Breakdown output for observation 214, influences of each variable of the prediction - red indicates lowering, and green heightening the prediction value
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:2-4-shap-214"></span>
<img src="images/2-4-shap_214.png" alt="Shap output for observation 214. Average impact of the variable on the prediction calculated with Break Down for 10 permutations, with boxplots showing the distribution of impacts from different permutations" width="100%" />
<p class="caption">
Figure 2.20: Shap output for observation 214. Average impact of the variable on the prediction calculated with Break Down for 10 permutations, with boxplots showing the distribution of impacts from different permutations
</p>
</div>
</div>
<div id="expert-opinions" class="section level3" number="2.4.6">
<h3><span class="header-section-number">2.4.6</span> Expert opinions</h3>
<p>According to experts there are two main types of diabetes:</p>
<ul>
<li><p><strong>type 1 diabetes</strong>, where the body does not make insulin. It is mostly caused by genetic and environmental factors</p></li>
<li><p><strong>type 2 diabetes</strong>, where the body does not make or use insulin well. It is the most common kind of diabetes. It is caused by several factors, including lifestyle factors and genes</p></li>
</ul>
<p>Unfortunately, we do not have any data about the type of diabetes that was found among the patients in the investigated dataset. However, since type 2 diabetes is the most common type, and some of the factors causing the different types are common, we will focus mostly on the risk factors for type 2 diabetes.</p>
<p><strong>Causes of type 2 diabetes</strong></p>
<p>According to the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), type 2 diabetes can be caused by several factors:</p>
<ul>
<li><p><strong>obesity and physical inactivity</strong> - Extra weight sometimes causes insulin resistance and is common in people with type 2 diabetes.</p></li>
<li><p><strong>insulin resistance</strong> - Type 2 diabetes usually begins with insulin resistance, a condition in which muscle, liver, and fat cells do not use insulin well. As a result, body needs more insulin to help glucose enter cells. At first, the pancreas makes more insulin to keep up with the higher demand. Over time, the pancreas cannot make enough insulin, and blood glucose level rises.</p></li>
<li><p><strong>genes and family history</strong> - As in type 1 diabetes, certain genes may make you more likely to develop type 2 diabetes. Genes also can increase the risk of type 2 diabetes by increasing a person’s tendency to become overweight or obese.</p></li>
<li><p><strong>ethnicity</strong> - Diabetes occurs more often in these racial/ethnic groups:</p>
<ul>
<li>African Americans</li>
<li>Alaska Natives</li>
<li>American Indians</li>
<li>Asian Americans</li>
<li>Hispanics/Latinos</li>
<li>Native Hawaiians</li>
<li>Pacific Islanders</li>
</ul></li>
<li><p><strong>age</strong> - Type 2 diabetes occurs most often among middle-aged and older adults, but it can also affect children.</p></li>
<li><p><strong>gestational diabetes</strong> - Gestational diabetes is the type of diabets that develops during pregnancy and is caused by the hormonal changes of pregnancy along with genetic and lifestyle factors. Women with a history of gestational diabetes have a greater chance of developing type 2 diabetes later in life.</p></li>
</ul>
<p><strong>Comparison with achieved results</strong></p>
<p>The causes of diabetes according to experts directly correspond with the columns in the explained dataset:</p>
<ul>
<li><code>plas</code> - plasma glucose concentration, can indicate whether the patient suffers from <strong>insulin resistance</strong></li>
<li><code>mass</code> - Body Mass Index (BMI) can be one of the indicators whether patients’ <strong>weight</strong> puts him at risk for type 2 diabetes</li>
<li><code>age</code>- <em>older</em> people are generally more likely to develop diabetes</li>
<li><code>pedi</code> - pedigree function is meant to be an indicator of patients’ risk for diabetes based on their <strong>genes and family history</strong></li>
<li><code>preg</code> - women that have been pregnant multiple times are more likely to develop <strong>gestational diabetes</strong>, and therefore, type 2 diabetes later in life.</li>
</ul>
<p>Since all the women in the dataset have the same <strong>ethnicity</strong>, it is not a factor that can be considered valuable in this experiment. Since American Indians are more prone to diabetes, the results of studies on this dataset should not be invoked when diagnosing patients of other ethnicities.</p>
</div>
<div id="conclusions-1" class="section level3" number="2.4.7">
<h3><span class="header-section-number">2.4.7</span> Conclusions</h3>
<p>The exploration of Diabetes dataset resulted in a discovery of initially unnoticeable NA values. After further examination of features distributions, we found out that <code>skin</code>, <code>insu</code>, <code>pres</code>, <code>mass</code> and <code>plas</code> have a significant amount of zero values which should not be present. After testing different datasets built by omitting and imputing variables or skipping observations, we concluded that the best solution would be removing <code>skin</code>, <code>insu</code> and <code>pres</code> variables and imputing <code>mass</code> and <code>plas</code>.</p>
<p>Moving forward we tested a number of popular Machine Learning models on our data. Measures like AUC, BAC and FNR showed us that Ranger and Ada models give us sufficient results to draw conclusions from.</p>
<p>After inspecting explanations on said models, it appears that, generally speaking, the bigger the values of variables other than <code>age</code> the higher the chance of positive diabetes test result. For Ada model, little to none impact by change of <code>age</code> after 35 years of living. For ranger, a peak in the prediction value around the <code>age</code> of 50. There is a sudden increase in prediction with <code>mass</code> reaching 30 being the border of obesity in BMI model. We observe almost no change for Ada prediction with different <code>pedi</code> values. There seems to be a slight increase in prediction with the 7th pregnancy.</p>
<p>In this scenario the causes of diabetes indicated by the XAI methods match the causes presented by the medical professionals. The Explainable Artificial Intelligence is an extremely helpful tool - it can be used to gain better understanding of the classification models, especially the ones used for making medical diagnosis, where this understanding is crucial to patients’ health and safety.</p>
<p>Further studies on diabetes prediction could include different ethnicity groups and genders. The medical data for models could be more complete and complex. Data with no missing values and potentially more features could also lead to more accurate models.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-xai1-ale" class="csl-entry">
Apley, D. W., &amp; Zhu, J. (2020). <span class="nocase">Visualizing the effects of predictor variables in black box supervised learning models</span>. <em>Journal of the Royal Statistical Society Series B</em>, <em>82</em>(4), 1059–1086. <a href="https://doi.org/10.1111/rssb.12377">https://doi.org/10.1111/rssb.12377</a>
</div>
<div id="ref-2-4-DALEX" class="csl-entry">
Biecek, P. (2018). <span class="nocase">DALEX: Explainers for Complex Predictive Models in R</span>. <em>Journal of Machine Learning Research</em>, <em>19</em>(84), 1–5. <a href="http://jmlr.org/papers/v19/18-416.html">http://jmlr.org/papers/v19/18-416.html</a>
</div>
<div id="ref-2-4-XAI" class="csl-entry">
Biecek, P., &amp; Burzykowski, T. (n.d.). <a href="https://ema.drwhy.ai/introduction.html">https://ema.drwhy.ai/introduction.html</a>
</div>
<div id="ref-EMA" class="csl-entry">
Biecek, P., &amp; Burzykowski, T. (2021). <em><span>Explanatory Model Analysis</span></em>. Chapman; Hall/CRC, New York. <a href="https://pbiecek.github.io/ema/">https://pbiecek.github.io/ema/</a>
</div>
<div id="ref-2-4-mlr" class="csl-entry">
Bischl, B., Lang, M., Kotthoff, L., Schiffner, J., Richter, J., Studerus, E., et al. (2016). <span class="nocase">mlr</span>: Machine learning in r. <em>Journal of Machine Learning Research</em>, <em>17</em>(170), 1–5. <a href="https://jmlr.org/papers/v17/15-066.html">https://jmlr.org/papers/v17/15-066.html</a>
</div>
<div id="ref-2-4-ada" class="csl-entry">
Culp, M., Johnson, K., &amp; Michailidis, G. (2016). <em>Ada: The r package ada for stochastic boosting</em>. <a href="https://CRAN.R-project.org/package=ada">https://CRAN.R-project.org/package=ada</a>
</div>
<div id="ref-2-4-pfi" class="csl-entry">
Fisher, A., Rudin, C., &amp; Dominici, F. (2018). <span class="nocase">All Models are Wrong, but Many are Useful: Learning a Variable’s Importance by Studying an Entire Class of Prediction Models Simultaneously</span>. <em>arXiv</em>. <a href="https://arxiv.org/abs/1801.01489">https://arxiv.org/abs/1801.01489</a>
</div>
<div id="ref-2-4-gbm" class="csl-entry">
Greenwell, B., Boehmke, B., Cunningham, J., &amp; Developers, G. (2020). <em>Gbm: Generalized boosted regression models</em>. <a href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>
</div>
<div id="ref-2-4-pdp" class="csl-entry">
Greenwell, B. M. (2017). <span class="nocase">pdp: An R Package for Constructing Partial Dependence Plots</span>. <em>The R Journal</em>, <em>9</em>(1), 421–436. <a href="http://doi.org/10.32614/RJ-2017-016">http://doi.org/10.32614/RJ-2017-016</a>
</div>
<div id="ref-2-4-randomForest" class="csl-entry">
Liaw, A., &amp; Wiener, M. (2002). Classification and regression by randomForest. <em>R News</em>, <em>2</em>(3), 18–22. <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>
</div>
<div id="ref-xai1-shapleyvalues" class="csl-entry">
Lundberg, S. M., &amp; Lee, S.-I. (2017). A unified approach to interpreting model predictions. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, &amp; R. Garnett (Eds.), <em>Advances in neural information processing systems 30</em> (pp. 4765–4774). Montreal: Curran Associates. <a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</a>
</div>
<div id="ref-2-4-ml-in-medicine" class="csl-entry">
Machine learning in medicine: A practical introduction. (n.d.). <a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-019-0681-4#ref-CR2">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-019-0681-4#ref-CR2</a>
</div>
<div id="ref-2-4-DALEXtra" class="csl-entry">
Maksymiuk, S., &amp; Biecek, P. (2020). <em><span class="nocase">DALEXtra: Extension for ’DALEX’ Package</span></em>. <a href="https://CRAN.R-project.org/package=DALEXtra">https://CRAN.R-project.org/package=DALEXtra</a>
</div>
<div id="ref-2-4-e1071" class="csl-entry">
Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., &amp; Leisch, F. (2020). <em>e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien</em>. <a href="https://CRAN.R-project.org/package=e1071">https://CRAN.R-project.org/package=e1071</a>
</div>
<div id="ref-2-4-stats" class="csl-entry">
R Core Team. (2021). <em>R: A language and environment for statistical computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>
</div>
<div id="ref-xai1-lime" class="csl-entry">
Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016). "<span class="nocase">Why should I trust you</span>?": Explaining the predictions of any classifier. In <em>Proceedings of the 22nd <span>ACM</span> <span>SIGKDD</span> international conference on knowledge discovery and data mining, KDD san francisco, CA</em> (pp. 1135–1144). New York, NY: Association for Computing Machinery.
</div>
<div id="ref-xai1-breakdown" class="csl-entry">
Staniak, M., &amp; Biecek, P. (2018). Explanations of model predictions with live and breakDown packages.
</div>
<div id="ref-2-4-cost" class="csl-entry">
Turney, P. D. (1995). Cost-sensitive classification: Empirical evaluationof a hybrid genetic decision tree induction algorithm. <a href="https://www.jair.org/index.php/jair/article/view/10129/23991">https://www.jair.org/index.php/jair/article/view/10129/23991</a>
</div>
<div id="ref-2-4-mice" class="csl-entry">
van Buuren, S., &amp; Groothuis-Oudshoorn, K. (2011). <span class="nocase">mice</span>: Multivariate imputation by chained equations in r. <em>Journal of Statistical Software</em>, <em>45</em>(3), 1–67. <a href="https://www.jstatsoft.org/v45/i03/">https://www.jstatsoft.org/v45/i03/</a>
</div>
<div id="ref-2-4-ranger" class="csl-entry">
Wright, M. N., &amp; Ziegler, A. (2017). <span class="nocase">ranger</span>: A fast implementation of random forests for high dimensional data in <span>C++</span> and <span>R</span>. <em>Journal of Statistical Software</em>, <em>77</em>(1), 1–17. <a href="https://doi.org/10.18637/jss.v077.i01">https://doi.org/10.18637/jss.v077.i01</a>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="how-to-predict-the-probability-of-subsequent-blood-donations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="how-the-price-of-the-house-is-influenced-by-neighborhood-xai-methods-for-interpretation-the-black-box-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mini-pw/2021L-WB-Book/edit/master/2-4-diabetes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
